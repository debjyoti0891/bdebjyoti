I"?<p>My keen interest in hardware technologies, coupled with my background in computer science, has driven me to pursue research in the direction of design automation algorithms and tools for architectures, for a variety of technologies. Recently, I am learning about the state-of-the-art in Deep Neural Networks~(NN) and understanding the NN strutures (<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">Alexnet</a>, <a href="https://arxiv.org/abs/1512.03385">Resnet</a>, etc).</p>

<p>In parallel, I have started using <a href="https://pytorch.org/">PyTorch</a> for implementation of DNNs. For the purpose of designing efficient NN accelerators, the first step is to find a way to extract an exact description of the NN graph. I found out the possiblity of finding the execution traces of the defined NNs using <a href="https://pytorch.org/docs/stable/jit.html#mixing-tracing-and-scripting">Torchscript</a> and then parsing them into a directed graph. However, this is almost an hack! A better alternative was to look at the Open Neural Network Exchange (<a href="https://onnx.ai/">ONNX</a>) format for NNs. Each ONNX model is self contained and can be accessed as a <a href="#proto">ProtoBuf</a> object. PyTorch and most other deep NN frameworks allows models to be directly written to ONNX format, which makes it a common representation to be used for the process of design automation of NN accelerators.</p>

<p>In the upcoming blogs, expect more details of design automation process for NN accelerators to be unveiled.</p>

<h3 id="references">References</h3>
<ul>
  <li><a name="alexnet"></a><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">ImageNet Classification with Deep ConvolutionalNeural Networks</a></li>
  <li><a name="resnet"></a><a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></li>
  <li><a name="proto"></a><a href="https://developers.google.com/protocol-buffers/docs/overview">Introduction to protocol buffers</a></li>
</ul>
:ET